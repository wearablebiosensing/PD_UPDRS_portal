{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9f7f1f",
   "metadata": {},
   "source": [
    "### Jupyter Notebook for MDPI itex glove data analysis\n",
    "# Steps: \n",
    "1. Check if Python libraries listed in imports (I used Python 3.8)\n",
    "2. Local copy of I-Tex glove dataset (Set variable dset_path in code cell below with dataset folder path in your PC)\n",
    "3. Run cells sequentially to extract features from LG, RG \n",
    "4. Evaluate feature significance with SHAP \n",
    "\n",
    "## Todos:\n",
    "1. Extract features suggested with MDPI reviewers [V,S] (Decrease in amplitude within activity, speed)\n",
    "2. Train using cross validation? (Or do proper train-test file split) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8494fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import signal\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "import datetime\n",
    "import scipy\n",
    "import plotly.express as px\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from itertools import cycle\n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import time\n",
    "\n",
    "#Hyper params\n",
    "# Base path of dataset \n",
    "dset_path = \"/Users/shehjarsadhu/Desktop/UniversityOfRhodeIsland/Graduate/WBL/Project_IOTEX/iotex-glove/PD\"\n",
    "\n",
    "np.random.seed(123)\n",
    "prom_val= (0.01, 4)\n",
    "width_val = (2,20)\n",
    "Dist_val = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4693d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsfel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3a95ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_peak_frequency(data, sampling_rate,n=1024):\n",
    "    \"\"\"Compute the peak frequency.\n",
    "\n",
    "    Requires Scipy\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 1d-array\n",
    "      Input signal in the time-domain.\n",
    "    sampling_rate : float\n",
    "      Sampling frequency of the data.\n",
    "    n : float\n",
    "      FFT points \n",
    "      (1024,2048)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    abs(peak_freq * sampling_rate) : float\n",
    "      Peak frequency.\n",
    "    \"\"\"\n",
    "    data = signal.detrend(data)\n",
    "    fft_data = np.fft.fft(data,n)\n",
    "#     freqs = np.fft.fftfreq(len(data))\n",
    "    freqs = np.fft.fftfreq(n)\n",
    "\n",
    "    peak_coefficient = np.argmax(np.abs(fft_data))\n",
    "    peak_freq = freqs[peak_coefficient]\n",
    "    return abs(peak_freq * sampling_rate)\n",
    "    \n",
    "def NormalizeData(data):\n",
    "    '''\n",
    "    Normalize data with max and min\n",
    "    '''\n",
    "\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def sampen(L, m, r):\n",
    "    '''\n",
    "    Sample entropy for given array L\n",
    "    '''\n",
    "    N = len(L)\n",
    "    B = 0.0\n",
    "    A = 0.0\n",
    "    \n",
    "    \n",
    "    # Split time series and save all templates of length m\n",
    "    xmi = np.array([L[i : i + m] for i in range(N - m)])\n",
    "    xmj = np.array([L[i : i + m] for i in range(N - m + 1)])\n",
    "\n",
    "    # Save all matches minus the self-match, compute B\n",
    "    B = np.sum([np.sum(np.abs(xmii - xmj).max(axis=1) <= r) - 1 for xmii in xmi])\n",
    "\n",
    "    # Similar for computing A\n",
    "    m += 1\n",
    "    xm = np.array([L[i : i + m] for i in range(N - m + 1)])\n",
    "\n",
    "    A = np.sum([np.sum(np.abs(xmi - xm).max(axis=1) <= r) - 1 for xmi in xm])\n",
    "\n",
    "    # Return SampEn\n",
    "    return -np.log(A / B)\n",
    "\n",
    "\n",
    "def peak_valley_analysis(data, Prominence=prom_val, Width = width_val,Distance=Dist_val):  \n",
    "    '''\n",
    "    Peak valley analysis for given data array, prominence value, width, minimum distance\n",
    "    Uses signal.find_peaks    \n",
    "    '''\n",
    "    data = signal.detrend(data)\n",
    "    peaks, properties = signal.find_peaks(data, prominence=Prominence, width=Width,distance=Distance)\n",
    "    valley, properties = signal.find_peaks(data*-1, prominence=Prominence, width=Width,distance=Distance)        \n",
    "            \n",
    "    p2p_dist = np.diff(peaks)\n",
    "    mean_p2p_dist = np.mean(p2p_dist)\n",
    "    std_p2p_dist = np.std(p2p_dist)\n",
    "    num_pk = len(peaks)\n",
    "    num_val = len(valley)\n",
    "\n",
    "#     if(num_pk == num_val):\n",
    "#         p2v_dist = np.abs(peaks-valley)\n",
    "#         mean_p2v_dist = np.mean(p2v_dist)\n",
    "#         std_p2v_dist = np.std(p2v_dist)\n",
    "#         p2v_height = np.abs(data[peaks]-data[valley])\n",
    "#         mean_p2v_height = np.mean(p2v_height)\n",
    "#         std_p2v_height = np.std(p2v_height)\n",
    "#     elif(num_pk > num_val):\n",
    "#         peaks = peaks[peaks<np.max(valley)]\n",
    "#         peaks = peaks[:num_val]\n",
    "#         p2v_dist = np.abs(peaks-valley)\n",
    "#         mean_p2v_dist = np.mean(p2v_dist)\n",
    "#         std_p2v_dist = np.std(p2v_dist)\n",
    "#         p2v_height = np.abs(data[valley]-data[peaks])\n",
    "#         mean_p2v_height = np.mean(p2v_height)\n",
    "#         std_p2v_height = np.std(p2v_height)\n",
    "#     elif(num_pk<num_val):\n",
    "#         valley = valley[valley<np.max(peaks)]\n",
    "#         valley = valley[:num_pk]\n",
    "#         p2v_dist = np.abs(peaks-valley)\n",
    "#         mean_p2v_dist = np.mean(p2v_dist)\n",
    "#         std_p2v_dist = np.std(p2v_dist)\n",
    "#         p2v_height = np.abs(data[peaks]-data[valley])\n",
    "#         mean_p2v_height = np.mean(p2v_height)\n",
    "#         std_p2v_height = np.std(p2v_height)\n",
    "#     num_pk = len(peaks)\n",
    "    return [mean_p2p_dist,std_p2p_dist]\n",
    "\n",
    "def bandpower(data, band, fs=64,  method='welch', window_sec=None, relative=False):\n",
    "    \"\"\"Compute the average power of the signal x in a specific frequency band.\n",
    "\n",
    "    Requires MNE-Python >= 0.14.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 1d-array\n",
    "      Input signal in the time-domain.\n",
    "    fs : float\n",
    "      Sampling frequency of the data.\n",
    "    band : list\n",
    "      Lower and upper frequencies of the band of interest.\n",
    "    method : string\n",
    "      Periodogram method: 'welch' or 'multitaper'\n",
    "    window_sec : float\n",
    "      Length of each window in seconds. Useful only if method == 'welch'.\n",
    "      If None, window_sec = (1 / min(band)) * 2.\n",
    "    relative : boolean\n",
    "      If True, return the relative power (= divided by the total power of the signal).\n",
    "      If False (default), return the absolute power.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    bp : float\n",
    "      Absoluteor relative band power.\n",
    "    \"\"\"\n",
    "    \n",
    "#     from scipy.signal import welch\n",
    "#     from scipy.integrate import simps\n",
    "#     from mne.time_frequency import psd_array_multitaper\n",
    "\n",
    "    band = np.asarray(band)\n",
    "    low, high = band\n",
    "\n",
    "    # Compute the modified periodogram (Welch)\n",
    "    if method == 'welch':\n",
    "        if window_sec is not None:\n",
    "            nperseg = window_sec * fs\n",
    "        else:\n",
    "            nperseg = (2 / low) * fs\n",
    "\n",
    "        freqs, psd = signal.welch(data, fs, nperseg=nperseg)\n",
    "\n",
    "    # Frequency resolution\n",
    "    freq_res = freqs[1] - freqs[0]\n",
    "\n",
    "    # Find index of band in frequency vector\n",
    "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
    "\n",
    "    # Integral approximation of the spectrum using parabola (Simpson's rule)\n",
    "    bp = scipy.integrate.simps(psd[idx_band], dx=freq_res)\n",
    "\n",
    "    if relative:\n",
    "        bp /= scipy.integrate.simps(psd, dx=freq_res)\n",
    "    return bp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        '''\n",
    "        Butterworth filter for given low and high frequency, sampling rate (fs) and order\n",
    "        '''\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        sos = signal.butter(order, [low, high], analog=False, btype='band', output='sos')\n",
    "        return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "\n",
    "        sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = signal.sosfilt(sos, data)\n",
    "        return y\n",
    "    \n",
    "#     if any(res.strftime('%Y%m%d-%H%M%S') in word for word in text_files):\n",
    "#         print(res.strftime('%Y%m%d-%H%M%S') +' is there inside the list!')\n",
    "#         return str(word)\n",
    "#     else:\n",
    "#         print(res.strftime('%Y%m%d-%H%M%S') +' is not there inside the list')\n",
    "#         return 0\n",
    "#     filter_object = filter(lambda a: res.strftime('%Y%m%d-%H%M%S') in a, text_files)\n",
    "#     text_file  = [k for k in text_files if res.strftime('%Y%m%d-%H%M%S')+\"_patient_form.txt\" in k]\n",
    "        \n",
    "\n",
    "def stride_trick(a, stride_length, stride_step):\n",
    "    \"\"\"\n",
    "    apply framing using the stride trick from numpy.\n",
    "\n",
    "    Args:\n",
    "        a (array) : signal array.\n",
    "        stride_length (int) : length of the stride.\n",
    "        stride_step (int) : stride step.\n",
    "\n",
    "    Returns:\n",
    "        blocked/framed array.\n",
    "    \"\"\"\n",
    "    nrows = ((a.size - stride_length) // stride_step) + 1\n",
    "    n = a.strides[0]\n",
    "    return np.lib.stride_tricks.as_strided(a,\n",
    "                                           shape=(nrows, stride_length),\n",
    "                                           strides=(stride_step*n, n))\n",
    "\n",
    "\n",
    "def framing(sig, fs=64, win_len=0.25, win_hop=0.125):\n",
    "    \"\"\"\n",
    "    transform a signal into a series of overlapping frames (=Frame blocking).\n",
    "\n",
    "    Args:\n",
    "        sig     (array) : a normalized and detrended signal.\n",
    "        fs        (int) : the sampling frequency of the signal we are working with.\n",
    "                          Default is 64.\n",
    "        win_len (float) : window length in sec.\n",
    "                          Default is 0.025.\n",
    "        win_hop (float) : step between successive windows in sec.\n",
    "                          Default is 0.01.\n",
    "\n",
    "    Returns:\n",
    "        array of frames.\n",
    "        frame length.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "        Uses the stride trick to accelerate the processing.\n",
    "    \"\"\"\n",
    "    # run checks and assertions\n",
    "    if win_len < win_hop: print(\"ParameterError: win_len must be larger than win_hop.\")\n",
    "\n",
    "    # compute frame length and frame step (convert from seconds to samples)\n",
    "    frame_length = win_len * fs\n",
    "    frame_step = win_hop * fs\n",
    "    signal_length = len(sig)\n",
    "    frames_overlap = frame_length - frame_step\n",
    "\n",
    "    # compute number of frames and left sample in order to pad if needed to make\n",
    "    # sure all frames have equal number of samples  without truncating any samples\n",
    "    # from the original signal\n",
    "    rest_samples = np.abs(signal_length - frames_overlap) % np.abs(frame_length - frames_overlap)\n",
    "    pad_signal = np.append(sig, np.array([0] * int(frame_step - rest_samples) * int(rest_samples != 0.)))\n",
    "\n",
    "    # apply stride trick\n",
    "    frames = stride_trick(pad_signal, int(frame_length), int(frame_step))\n",
    "    return frames, frame_length\n",
    "\n",
    "\n",
    "def _calculate_normalized_short_time_energy(frames):\n",
    "    '''Calculates the short time FFT band energy'''\n",
    "\n",
    "    return np.sum(np.abs(np.fft.rfft(a=frames, n=len(frames)))**2, axis=-1) / len(frames)**2\n",
    "\n",
    "\n",
    "def naive_frame_energy_vad(sig, fs=64, threshold=0, win_len=0.25, win_hop=0.25, E0=1e7):\n",
    "    '''\n",
    "    For detecting signal activity (windowing activity data)\n",
    "    '''\n",
    "    # framing\n",
    "    frames, frames_len = framing(sig=sig, fs=fs, win_len=win_len, win_hop=win_hop)\n",
    "\n",
    "    # compute short time energies to get voiced frames\n",
    "    energy = _calculate_normalized_short_time_energy(frames)\n",
    "    log_energy = 10 * np.log10(energy / E0)\n",
    "\n",
    "    # normalize energy to 0 dB then filter and format\n",
    "    energy = scipy.signal.medfilt(log_energy, 5)\n",
    "    energy = np.repeat(energy, frames_len)\n",
    "#     print(energy.shape)\n",
    "    mean_energy = np.mean(energy)\n",
    "    threshold = np.average([mean_energy,np.amin(energy)])\n",
    "    # compute vad and get speech frames\n",
    "    vad     = np.array(energy > threshold, dtype=sig.dtype)\n",
    "    #find and remove re-detection\n",
    "    diff_vad = np.diff(vad)\n",
    "#     print(threshold,np.where(diff_vad==-1)[0].shape)\n",
    "    if(len(np.where(diff_vad==-1)[0])!=0):\n",
    "#         print(\"here\")\n",
    "        pos_neg = np.where(diff_vad==-1)[0]\n",
    "#         print(pos_neg)\n",
    "        vad[int(pos_neg[0]):] = 0\n",
    "#     print(threshold)\n",
    "\n",
    "\n",
    "    vframes = np.array(frames.flatten()[np.where(vad==1)], dtype=sig.dtype)\n",
    "    \n",
    "\n",
    "    return energy, vad, np.array(vframes, dtype=np.float64)\n",
    "\n",
    "\n",
    "def multi_plots(data, titles, fs, plot_rows, step=1, colors=[\"b\", \"r\", \"m\", \"g\", \"b\", \"y\"]):\n",
    "    # first fig\n",
    "    plt.figure()\n",
    "    plt.subplots(plot_rows, 1, figsize=(20, 10))\n",
    "    plt.subplots_adjust(left=0.125, right=0.9, bottom=0.1, top=0.99, wspace=0.4, hspace=0.99)\n",
    "\n",
    "    for i in range(plot_rows):\n",
    "        plt.subplot(plot_rows, 1, i+1)\n",
    "        y = data[i]\n",
    "        plt.plot([i/fs for i in range(0, len(y), step)], y, colors[i])\n",
    "        plt.gca().set_title(titles[i])\n",
    "    plt.show()\n",
    "\n",
    "    # second fig\n",
    "    sig, vad = data[0], data[-2]\n",
    "    # plot VAD and orginal signal\n",
    "    plt.subplots(1, 1, figsize=(20, 10))\n",
    "    plt.plot([i/fs for i in range(len(sig))], sig, label=\"Signal\")\n",
    "    plt.plot([i/fs for i in range(len(vad))], max(sig)*vad, label=\"VAD\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def zcr(sig):\n",
    "    ''' \n",
    "    Calculates zero crossing rate of a given signal after detrending and normalizing\n",
    "    '''\n",
    "    sig = signal.detrend(sig)\n",
    "    sig_norm = [sig- min(sig)]\n",
    "    mval = max(abs(i) for i in sig)\n",
    "    sig = np.array([i / mval for i in sig])\n",
    "    val = ((sig[:-1] * sig[1:]) < 0).sum()\n",
    "    return val\n",
    "\n",
    "def mean_freq(sig, fs):\n",
    "    '''\n",
    "    Mean frequency within given signal\n",
    "    '''    \n",
    "    Y = np.abs(np.fft.rfft(sig)) \n",
    "    power_spectrum = Y**2\n",
    "    freq = np.fft.rfftfreq(len(sig), fs)\n",
    "    # Then calculate (weighted) mean\n",
    "    return np.sum(freq * power_spectrum / np.sum(power_spectrum)) # This should equal to the formula in your image.\n",
    "\n",
    "def rmsValue(sig):\n",
    "    '''\n",
    "    Finds root mean square of a given signal\n",
    "    '''\n",
    "\n",
    "    square = 0\n",
    "    mean = 0.0\n",
    "    root = 0.0\n",
    "    n = len(sig)\n",
    "     \n",
    "    #Calculate square\n",
    "    for i in range(0,n):\n",
    "        square += (sig[i]**2)\n",
    "     \n",
    "    #Calculate Mean\n",
    "    mean = (square / (float)(len(sig)))\n",
    "     \n",
    "    #Calculate Root\n",
    "    root = math.sqrt(mean)\n",
    "     \n",
    "    return root\n",
    " \n",
    "# Provide flex sigs for analysis, \n",
    "# returns [ft_mean_p2p_dist,ft_std_p2p_dist,ft_mean_p2v_dist,ft_std_p2v_dist,ft_mean_p2v_height,ft_std_p2v_height,ft_pdenergy,ft_dysenergy,ft_mean_freq, ft_rms\n",
    "def kinetic_analysis(sig,fs,order,lf,hf,prom_val,width_val,Dist_val,detect_theshold=-20):\n",
    "    '''\n",
    "    Computes peak-valley locations and band energy within given flexion/inertial signal  (For hand flip, finger tap, finger to nose, hand open-close)\n",
    "\n",
    "    TODO: Find features for start middle and ending windows\n",
    "\n",
    "    '''\n",
    "    sig = signal.detrend(sig)\n",
    "    b, a = scipy.signal.butter(order, [lf*2/fs, hf*2/fs], 'band') \n",
    "    sig = scipy.signal.filtfilt(b, a, sig)\n",
    "    sig_feats = []\n",
    "    pdenergy = bandpower(sig, [5, 10], fs, 'welch',relative=True)\n",
    "    dysenergy = bandpower(sig, [2,5], fs, 'welch',relative=True)\n",
    "    energy, vad, detected = naive_frame_energy_vad(sig, fs=fs, threshold=detect_theshold,\n",
    "                                                     win_len=0.25, win_hop=0.25)            \n",
    "    sig_feats = peak_valley_analysis(detected, Prominence=prom_val, Width = width_val,Distance=Dist_val)\n",
    "    sig_feats.append(pdenergy)\n",
    "    sig_feats.append(dysenergy)\n",
    "    sig_psd = bandpower(sig, [2, 20], fs, 'welch',relative=True) \n",
    "    sig_feats.append(sig_psd)\n",
    "    sig_feats.append(mean_freq(sig, fs))\n",
    "    sig_feats.append(rmsValue(detected))\n",
    "                \n",
    "    return sig_feats\n",
    "    \n",
    "                \n",
    "    \n",
    "                \n",
    "# Provide inertial signals (acc[x,y,z] & gyr[x,y,z]) for either RH or HH task\n",
    "# Returns seg1_acc_pdenergy,seg1_acc_dysenergy,seg1_acc_df,seg1_acc_mf,seg1_acc_std,seg1_acc_sent,seg1_acc_psd,seg1_acc_rms\\,seg1_gyr_pdenergy,seg1_gyr_dys_energy,seg1_gyr_df,seg1_gyr_mf,seg1_gyr_std,seg1_gyr_sent,seg1_gyr_psd,seg1_gyr_rmsseg2_acc_pdenergy,seg2_acc_dysenergy,seg2_acc_df,seg2_acc_mf,seg2_acc_std,seg2_acc_sent,seg2_acc_psd,seg2_acc_rms\\,seg2_gyr_pdenergy,seg2_gyr_dysenergy,seg2_gyr_df,seg2_gyr_mf,seg2_gyr_std,seg2_gyr_sent,seg2_gyr_psd,seg2_gyr_rms\n",
    "def stationary_analysis(inertial_sigs,fs):\n",
    "    '''\n",
    "    Computes band energy and other signal features inertial signals  (For resting hands, hold out hands tasks)\n",
    "\n",
    "    TODO: Find features for start middle and ending windows\n",
    "\n",
    "    '''\n",
    "    inertial_sigs = np.transpose(inertial_sigs)\n",
    "#     print(inertial_sigs.shape)\n",
    "    sig_seg_len = len(inertial_sigs[0])//2\n",
    "    [x ** 2 for x in range(10) if x % 2 == 0]\n",
    "    acc_rms_raw = np.array([rmsValue(inertial_sigs[:3,i]) for i in range(inertial_sigs.shape[1])])\n",
    "\n",
    "#        np.sqrt(sum(inertial_sigs[0]**2))+ np.sqrt(sum(inertial_sigs[1]**2))+np.sqrt(sum(inertial_sigs[2]**2))\n",
    "    gyr_rms_raw = np.array([rmsValue(inertial_sigs[3:,i]) for i in range(inertial_sigs.shape[1])])\n",
    "\n",
    "    b, a = scipy.signal.butter(2, [1*2/fs, 30*2/fs], 'band') \n",
    "    # Based on : An automated methodology for levodopa-induced dyskinesia: Assessment based on gyroscope and accelerometer signals\n",
    "    acc_rms = scipy.signal.filtfilt(b, a, acc_rms_raw)\n",
    "    gyr_rms = scipy.signal.filtfilt(b, a, gyr_rms_raw)\n",
    "    r_val = r_val = np.mean(np.std(acc_rms))\n",
    "    sig_feats = []    \n",
    "    seg1_acc_pdenergy = bandpower(acc_rms[:sig_seg_len], [5, 10], fs, 'welch',relative=True)\n",
    "    sig_feats.append(seg1_acc_pdenergy)\n",
    "    seg1_acc_dysenergy = bandpower(acc_rms[:sig_seg_len], [2, 5], fs, 'welch',relative=True)\n",
    "    sig_feats.append(seg1_acc_dysenergy)\n",
    "    seg1_acc_df = extract_peak_frequency(acc_rms[:sig_seg_len],64)\n",
    "    sig_feats.append(seg1_acc_df)\n",
    "    seg1_acc_mf = mean_freq(acc_rms[:sig_seg_len], fs)\n",
    "    sig_feats.append(seg1_acc_mf)\n",
    "    seg1_acc_std = np.std(acc_rms[:sig_seg_len])\n",
    "    sig_feats.append(seg1_acc_std)\n",
    "    seg1_acc_sent = sampen(acc_rms[:sig_seg_len], m=2, r=r_val)\n",
    "    sig_feats.append(seg1_acc_sent)\n",
    "    seg1_acc_psd = bandpower(acc_rms_raw[:sig_seg_len], [2, 20], fs, 'welch',relative=True) \n",
    "    sig_feats.append(seg1_acc_psd)\n",
    "    \n",
    "    seg1_gyr_pdenergy = bandpower(gyr_rms[:sig_seg_len], [2, 5], fs, 'welch',relative=True)\n",
    "    sig_feats.append(seg1_gyr_pdenergy)\n",
    "    seg1_gyr_dys_energy = bandpower(gyr_rms[:sig_seg_len], [5, 10], fs, 'welch',relative=True)\n",
    "    sig_feats.append(seg1_gyr_dys_energy)\n",
    "    seg1_gyr_df = extract_peak_frequency(gyr_rms[:sig_seg_len],fs)\n",
    "    sig_feats.append(seg1_gyr_df)\n",
    "    seg1_gyr_mf = mean_freq(gyr_rms[:sig_seg_len], fs)\n",
    "    sig_feats.append(seg1_gyr_mf)\n",
    "    seg1_gyr_std = np.std(gyr_rms[:sig_seg_len])\n",
    "    sig_feats.append(seg1_gyr_std)\n",
    "    seg1_gyr_sent = sampen(gyr_rms[:sig_seg_len], m=2, r=r_val)\n",
    "    sig_feats.append(seg1_gyr_sent)\n",
    "    seg1_gyr_psd = bandpower(gyr_rms_raw[:sig_seg_len], [2, 20], fs, 'welch',relative=True) \n",
    "    sig_feats.append(seg1_gyr_psd)\n",
    "\n",
    "    seg2_acc_pdenergy = bandpower(acc_rms[sig_seg_len:], [2, 5], fs, 'welch',relative=True)\n",
    "    sig_feats.append(seg2_acc_pdenergy)\n",
    "    seg2_acc_dysenergy = bandpower(acc_rms[sig_seg_len:], [5, 10], fs, 'welch',relative=True)\n",
    "    sig_feats.append(seg2_acc_dysenergy)\n",
    "    seg2_acc_df = extract_peak_frequency(acc_rms[sig_seg_len:],fs)\n",
    "    sig_feats.append(seg2_acc_df)\n",
    "    seg2_acc_mf = mean_freq(acc_rms[sig_seg_len:], fs)\n",
    "    sig_feats.append(seg2_acc_mf)\n",
    "    seg2_acc_std = np.std(acc_rms[sig_seg_len:])\n",
    "    sig_feats.append(seg2_acc_std)\n",
    "    seg2_acc_sent = sampen(acc_rms[sig_seg_len:], m=2, r=r_val)\n",
    "    sig_feats.append(seg2_acc_sent)\n",
    "    seg2_acc_psd = bandpower(acc_rms_raw[sig_seg_len:], [2, 20], 64, 'welch',relative=True) \n",
    "    sig_feats.append(seg2_acc_psd)\n",
    "    sig_acc_zc = zcr(acc_rms)\n",
    "    sig_feats.append(sig_acc_zc)\n",
    "\n",
    "    seg2_gyr_pdenergy = bandpower(gyr_rms[sig_seg_len:], [2, 5], 64, 'welch',relative=True)\n",
    "    sig_feats.append(seg2_gyr_pdenergy)\n",
    "    seg2_gyr_dysenergy = bandpower(gyr_rms[sig_seg_len:], [5, 10], 64, 'welch',relative=True)\n",
    "    sig_feats.append(seg2_gyr_dysenergy)\n",
    "    seg2_gyr_df = extract_peak_frequency(gyr_rms[sig_seg_len:],64)\n",
    "    sig_feats.append(seg2_gyr_df)\n",
    "    seg2_gyr_mf = mean_freq(gyr_rms[sig_seg_len:], 64)\n",
    "    sig_feats.append(seg2_gyr_mf)\n",
    "    seg2_gyr_std = np.std(gyr_rms[sig_seg_len:])\n",
    "    sig_feats.append(seg2_gyr_std)\n",
    "    seg2_gyr_sent = sampen(gyr_rms[sig_seg_len:], m=2, r=r_val)\n",
    "    sig_feats.append(seg2_gyr_sent)\n",
    "    seg2_gyr_psd = bandpower(gyr_rms_raw[sig_seg_len:], [2, 20], 64, 'welch',relative=True) \n",
    "    sig_feats.append(seg2_gyr_psd)\n",
    "    sig_gyr_zc = zcr(gyr_rms)\n",
    "\n",
    "    sig_feats.append(sig_gyr_zc)\n",
    "\n",
    "    \n",
    "\n",
    "    return sig_feats\n",
    "\n",
    "                \n",
    "    \n",
    "\n",
    "\n",
    "                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61e41ae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part No: 1\n",
      "RG cnt: 21, LG cnt: 21, Txt cnt: 20\n",
      "Total RG files: 21\n",
      "File No: 0, Med: 3\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (1, 84) \n",
      "File No: 1, Med: 3\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (2, 84) \n",
      "File No: 2, Med: 3\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (3, 84) \n",
      "File No: 3, Med: 3\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (4, 84) \n",
      "File No: 4, Med: 2\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (5, 84) \n",
      "File No: 5, Med: 3\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (6, 84) \n",
      "File No: 6, Med: 3\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (7, 84) \n",
      "File No: 7, Med: 2\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (8, 84) \n",
      "File No: 8, Med: 3\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (9, 84) \n",
      "File No: 9, Med: 3\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (10, 84) \n",
      "File No: 10, Med: 1\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (11, 84) \n",
      "File No: 11, Med: 2\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (12, 84) \n",
      "File No: 12, Med: 3\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (13, 84) \n",
      "File No: 13, Med: 3\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (14, 84) \n",
      "File No: 14, Med: 2\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (15, 84) \n",
      "File No: 15, Med: 3\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (16, 84) \n",
      "File No: 16, Med: 3\n",
      "File too small, skipping\n",
      "File No: 17, Med: 0\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (17, 84) \n",
      "File No: 18, Med: 3\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (18, 84) \n",
      "File No: 19, Med: 0\n",
      "FT feat len - 7 \n",
      "tot feat len - 84 \n",
      "Total RG feat len - (19, 84) \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-99152a260a7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mch_rg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrg_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#random.choice(rg_files)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mdf_rg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch_rg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mch_form\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_num\u001b[0m\u001b[0;34m]\u001b[0m     \u001b[0;31m#Open questionnaire and find medication intake period\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mmy_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch_form\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mmedication_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmed_usage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmy_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "# Print the current working directory\n",
    "# print(\"Current working directory: {0}\".format(cwd))\n",
    "# Medication intake labels\n",
    "med_usage = {\n",
    "  \"0_to_1_hrs\": 0,\n",
    "  \"1_to_2_hrs\": 1,\n",
    "  \"2_to_3_hrs\": 2,\n",
    "  \"4_plus\":3,\n",
    "  \"1_to_2hrs\": 1,\n",
    "}\n",
    "channels = ['index']\n",
    "cnames = [\"ft_mean_p2p_dist\",\"ft_std_p2p_dist\",\n",
    "#\"ft_std_p2v_dist\",\"ft_mean_p2v_height\",\"ft_std_p2v_height\",\n",
    "\"ft_pdenergy\",\"ft_dysenergy\",\"ft_psd\",\"ft_mean_freq\",\"ft_rms\",\n",
    "\"hh_seg1_acc_pdenergy\",\"hh_seg1_acc_dysenergy\",\"hh_seg1_acc_df\",\n",
    "\"hh_seg1_acc_mf\",\"hh_seg1_acc_std\",\"hh_seg1_acc_sent\",\"hh_seg1_acc_psd\",\n",
    "\"hh_seg1_gyr_pdenergy\",\"hh_seg1_gyr_dysenergy\",\n",
    "\"hh_seg1_gyr_df\",\"hh_seg1_gyr_mf\",\"hh_seg1_gyr_std\",\"hh_seg1_gyr_sent\",\n",
    "\"hh_seg1_gyr_psd\",\"hh_seg2_acc_pdenergy\",\n",
    "\"hh_seg2_acc_dysenergy\",\"hh_seg2_acc_df\",\"hh_seg2_acc_mf\",\n",
    "\"hh_seg2_acc_std\",\"hh_seg2_acc_sent\",\"hh_seg2_acc_psd\", \"hh_acc_zc\",\n",
    "\"hh_seg2_gyr_pdenergy\",\"hh_seg2_gyr_dysenergy\",\"hh_seg2_gyr_df\",\"hh_seg2_gyr_mf\",\"hh_seg2_gyr_std\",\n",
    "\"hh_seg2_gyr_sent\",\"hh_seg2_gyr_psd\",\"hh_gyr_zc\",\n",
    "\"rh_seg1_acc_pdenergy\",\"rh_seg1_acc_dysenergy\",\"rh_seg1_acc_df\",\n",
    "\"rh_seg1_acc_mf\",\"rh_seg1_acc_std\",\"rh_seg1_acc_sent\",\"rh_seg1_acc_psd\",\n",
    "\"rh_seg1_gyr_pdenergy\",\"rh_seg1_gyr_dysenergy\",\n",
    "\"rh_seg1_gyr_df\",\"rh_seg1_gyr_mf\",\"rh_seg1_gyr_std\",\"rh_seg1_gyr_sent\",\n",
    "\"rh_seg1_gyr_psd\",\"rh_seg2_acc_pdenergy\",\n",
    "\"rh_seg2_acc_dysenergy\",\"rh_seg2_acc_df\",\"rh_seg2_acc_mf\",\n",
    "\"rh_seg2_acc_std\",\"rh_seg2_acc_sent\",\"rh_seg2_acc_psd\",\"rh_acc_zc\",\n",
    "\"rh_seg2_gyr_pdenergy\",\"rh_seg2_gyr_dysenergy\",\"rh_seg2_gyr_df\",\"rh_seg2_gyr_mf\",\"rh_seg2_gyr_std\",\n",
    "\"rh_seg2_gyr_sent\",\"rh_seg2_gyr_psd\",\"rh_gyr_zc\", \n",
    "\"fn_mean_p2p_dist\",\"fn_std_p2p_dist\",#\"fn_mean_p2v_dist\",\n",
    "# \"fn_std_p2v_dist\",\"fn_mean_p2v_height\",\"fn_std_p2v_height\",\n",
    "\"fn_pdenergy\",\"fn_dysenergy\",\"fn_psd\",\"fn_mean_freq\",\"fn_rms\",\n",
    "\"hf_mean_p2p_dist\",\"hf_std_p2p_dist\",#\"hf_mean_p2v_dist\",\n",
    "#\"hf_std_p2v_dist\",\"hf_mean_p2v_height\",\"hf_std_p2v_height\",\n",
    "\"hf_pdenergy\",\"hf_dysenergy\",\"hf_psd\",\"hf_mean_freq\",\"hf_rms\",\"fno\",\"pno\",\"med_status\"]\n",
    "feat_rg = []\n",
    "feat_rg_tsfresh = []\n",
    "feat_rg_tsfresh_col = []\n",
    "for i in range(4):\n",
    "    pno = i+1\n",
    "    print(\"Part No: {}\".format(pno))\n",
    "    # csv_files = glob.glob('C:/Users/dan95/Desktop/Participant1/**/*.csv',recursive=True)\n",
    "    dset_csv_fpath = dset_path +'/Participant'+str(pno)+'/**/*.csv'\n",
    "    label_text_fpath = dset_path +'/Participant'+str(pno)+'/**/*.txt'\n",
    "\n",
    "    csv_files = glob.glob(dset_csv_fpath,recursive=True)\n",
    "    text_files = glob.glob(label_text_fpath,recursive=True)\n",
    "    rg_files = [s for s in csv_files if \"rg_\" in s]\n",
    "    lg_files = [s for s in csv_files if \"lg_\" in s]\n",
    "    lg_acts = [0,2,4,6,7,9]\n",
    "    rg_acts = [1,3,5,6,8,9]\n",
    "    print(\"RG cnt: {}, LG cnt: {}, Txt cnt: {}\".format(len(rg_files),len(lg_files),len(text_files)))# print(sorted(csv_files))\n",
    "    # print(glob.glob(csv_files))\n",
    "    # plot_channels = ['index','thumb','pitch','roll']\n",
    "    rg_act_no = 1\n",
    "    dist_ft = 0\n",
    "    tot_files = len(rg_files)\n",
    "    print(\"Total RG files: {}\".format(tot_files))\n",
    "    lf = 1\n",
    "    hf = 10\n",
    "    b, a = scipy.signal.butter(2, [lf*2/64, hf*2/64], 'band')\n",
    "    # plot results\n",
    "    # multi_plots(data=[sig, energy, vad, detected],\n",
    "    #             titles=[\"Input signal (activity + idle)\", \"Short time energy\",\n",
    "    #                     \"Activity detection\", \"Detected signal\"],\n",
    "    #             fs=64, plot_rows=4, step=1)\n",
    "\n",
    "\n",
    "    # Extract RG FT, HH, RH task features (Mean Peak Distance, Std of distance, Mean Peak Height, Std of height, PSD band energy[2-10Hz])\n",
    "    # Activity codes:\n",
    "    # 0: Left hand finger tap\n",
    "    # 1: Right hand finger tap\n",
    "    # 2: Left hand open close\n",
    "    # 3: Right hand open close\n",
    "    # 4: Left hand flip\n",
    "    # 5: Right hand flip \t\n",
    "    # 6: Both hands out\n",
    "    # 7: Left finger to nose\n",
    "    # 8: Right finger to nose\t\n",
    "    # 9: Hold out hand\n",
    "\n",
    "#     df_rg = pd.DataFrame([],columns =cnames)\n",
    "    for file_num in range(0,tot_files):\n",
    "        ch_rg = rg_files[file_num] #random.choice(rg_files)\n",
    "        df_rg = pd.read_csv(ch_rg,)\n",
    "        ch_form = text_files[file_num]     #Open questionnaire and find medication intake period \n",
    "        my_file = open(ch_form, \"r\")\n",
    "        medication_status = med_usage[my_file.read().split(\"\\n\")[4].split(\"=\")[1]]\n",
    "        print(\"File No: {}, Med: {}\" .format(file_num,medication_status))\n",
    "\n",
    "    #     sig = scipy.signal.filtfilt(b, a, df_rg[df_rg['activity'] == rg_act_no][channels].values)\n",
    "#         try:\n",
    "        index_sig = df_rg[df_rg['activity'] == rg_act_no]['index'].values\n",
    "        if len(index_sig)< 256:\n",
    "            print(\"File too small, skipping\")\n",
    "            continue\n",
    "        ## FT section\n",
    "        sig_feats = kinetic_analysis(index_sig,64,order=2,lf=1,hf=30, prom_val= (0.01, None), width_val = (2,20) ,Dist_val=5,detect_theshold=0)\n",
    "#         tsfresh_feats = extract_features(df_rg[[\"index\",\"pitch\",\"roll\"]],\n",
    "#                      default_fc_parameters=settings,\n",
    "#                      # we impute = remove all NaN features automatically\n",
    "#                      impute_function=impute)\n",
    "#         feat_rg_tsfresh = tsfresh_feats_ft.columns\n",
    "        print(\"FT feat len - {} \".format(len(sig_feats)))\n",
    "        ch_ = [\"ax\",\"ay\",\"az\",\"gx\",\"gy\",\"gz\"]\n",
    "        # sig = butter_bandpass_filter(df_rg[df_rg['activity'] == rg_act_no]['index'].values,0.1,30,64)\n",
    "        ## Extact features for HH task in sections 1 & 2 for accel and gyro [rms accel, dominant freq, mean freq,  ]\n",
    "        hh_feats = stationary_analysis(df_rg[df_rg['activity'] == 6][ch_].values,64)\n",
    "#             print(\"HH feat len - {} \".format(len(hh_feats)))\n",
    "        sig_feats.extend(hh_feats)\n",
    "#             print(\"tot feat len - {} \".format(len(sig_feats)))\n",
    "\n",
    "         ## Extact features for RH task in sections 1 & 2 for accel and gyro [rms accel, dominant freq, mean freq,  ]\n",
    "        rh_feats = stationary_analysis(df_rg[df_rg['activity'] == 9][ch_].values,64)\n",
    "#             print(\"RH feat len - {} \".format(len(rh_feats)))\n",
    "        sig_feats.extend(rh_feats)\n",
    "        fn_feats = kinetic_analysis(df_rg[df_rg['activity'] == 8]['pitch'],64,order=2,lf=1,hf=20, prom_val= (0.05,None), width_val = (None,20) ,Dist_val=5,detect_theshold=0)\n",
    "        sig_feats.extend(fn_feats)\n",
    "        hf_feats = kinetic_analysis(df_rg[df_rg['activity'] == 5]['pitch'],64,order=2,lf=0.1,hf=20, prom_val= (0.05,None), width_val = (None, 20) ,Dist_val=5,detect_theshold=0)\n",
    "        sig_feats.extend(hf_feats)\n",
    "\n",
    "#             print(\"tot feat len - {} \".format(len(sig_feats)))\n",
    "        sig_feats.append(file_num)\n",
    "#             print(\"tot feat len - {} \".format(len(sig_feats)))\n",
    "        sig_feats.append(pno)\n",
    "#             print(\"tot feat len - {} \".format(len(sig_feats)))\n",
    "        sig_feats.append(medication_status)\n",
    "        print(\"tot feat len - {} \".format(len(sig_feats)))\n",
    "        feat_rg.append(sig_feats)\n",
    "#         feat_rg_ts_fresh.append(tsfresh_feats_ft.values)\n",
    "        print(\"Total RG feat len - {} \".format(np.array(feat_rg).shape))\n",
    "\n",
    "            #         print(peak_valley_feats)\n",
    "#         except ValueError:\n",
    "#             print(\"Error in: {}\".format(file_num))\n",
    "#             continue\n",
    "feat_arr = np.transpose(feat_rg)\n",
    "print(len(feat_rg))\n",
    "# df_rg = pd.DataFrame(feat_rg, columns = cnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c80ec1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "# Print the current working directory\n",
    "# print(\"Current working directory: {0}\".format(cwd))\n",
    "med_usage = {\n",
    "  \"0_to_1_hrs\": 0,\n",
    "  \"1_to_2_hrs\": 1,\n",
    "  \"2_to_3_hrs\": 2,\n",
    "  \"4_plus\":3,\n",
    "  \"1_to_2hrs\": 1,\n",
    "}\n",
    "channels = ['index']\n",
    "\n",
    "feat_lg = []\n",
    "\n",
    "for i in range(4):\n",
    "    pno = i+1\n",
    "    print(\"Part No: {}\".format(pno))\n",
    "    dset_csv_fpath = dset_path +'/Participant'+str(pno)+'/**/*.csv'\n",
    "    label_text_fpath = dset_path +'/Participant'+str(pno)+'/**/*.txt'\n",
    "\n",
    "    csv_files = glob.glob(dset_csv_fpath,recursive=True)\n",
    "    text_files = glob.glob(label_text_fpath,recursive=True)\n",
    "    rg_files = [s for s in csv_files if \"rg_\" in s]\n",
    "    lg_files = [s for s in csv_files if \"lg_\" in s]\n",
    "    lg_acts = [0,2,4,6,7,9]\n",
    "    rg_acts = [1,3,5,6,8,9]\n",
    "    print(\"RG cnt: {}, LG cnt: {}, Txt cnt: {}\".format(len(rg_files),len(lg_files),len(text_files)))# print(sorted(csv_files))\n",
    "    # print(glob.glob(csv_files))\n",
    "    # plot_channels = ['index','thumb','pitch','roll']\n",
    "    rg_act_no = 1\n",
    "    dist_ft = 0\n",
    "    tot_files = len(rg_files)\n",
    "    lf = 1\n",
    "    hf = 10\n",
    "    b, a = scipy.signal.butter(2, [lf*2/64, hf*2/64], 'band')\n",
    "    \n",
    "    # plot results\n",
    "    # multi_plots(data=[sig, energy, vad, detected],\n",
    "    #             titles=[\"Input signal (activity + idle)\", \"Short time energy\",\n",
    "    #                     \"Activity detection\", \"Detected signal\"],\n",
    "    #             fs=64, plot_rows=4, step=1)\n",
    "\n",
    "\n",
    "    # Extract RG FT, HH, RH task features (Mean Peak Distance, Std of distance, Mean Peak Height, Std of height, PSD band energy[2-10Hz])\n",
    "\n",
    "#     df_rg = pd.DataFrame([],columns =cnames)\n",
    "    for file_num in range(0,tot_files):\n",
    "        ch_lg = lg_files[file_num] #random.choice(rg_files)\n",
    "        df_lg = pd.read_csv(ch_lg)\n",
    "        ch_form = text_files[file_num]     #Open questionnaire and find medication intake period \n",
    "        my_file = open(ch_form, \"r\")\n",
    "        medication_status = med_usage[my_file.read().split(\"\\n\")[4].split(\"=\")[1]]\n",
    "        print(\"File No: {}, Med: {}\" .format(file_num,medication_status))\n",
    "\n",
    "    #     sig = scipy.signal.filtfilt(b, a, df_rg[df_rg['activity'] == rg_act_no][channels].values)\n",
    "        try:\n",
    "            index_sig = df_lg[df_lg['activity'] == 0]['index'].values\n",
    "            if len(index_sig)< 256:\n",
    "                print(\"File too small, skipping\")\n",
    "                continue\n",
    "            ## FT section\n",
    "            sig_feats = kinetic_analysis(index_sig,64,order=2,lf=1,hf=30, prom_val= (0.01, None), width_val = (2,20) ,Dist_val=5,detect_theshold=0)\n",
    "            \n",
    "            print(\"FT feat len - {} \".format(len(sig_feats)))\n",
    "            ch_ = [\"ax\",\"ay\",\"az\",\"gx\",\"gy\",\"gz\"]\n",
    "            # sig = butter_bandpass_filter(df_rg[df_rg['activity'] == rg_act_no]['index'].values,0.1,30,64)\n",
    "            ## Extact features for HH task in sections 1 & 2 for accel and gyro [rms accel, dominant freq, mean freq,  ]\n",
    "            hh_feats = stationary_analysis(df_lg[df_lg['activity'] == 6][ch_].values,64)\n",
    "    #             print(\"HH feat len - {} \".format(len(hh_feats)))\n",
    "            sig_feats.extend(hh_feats)\n",
    "    #             print(\"tot feat len - {} \".format(len(sig_feats)))\n",
    "\n",
    "             ## Extact features for RH task in sections 1 & 2 for accel and gyro [rms accel, dominant freq, mean freq,  ]\n",
    "            rh_feats = stationary_analysis(df_lg[df_lg['activity'] == 9][ch_].values,64)\n",
    "#             print(\"RH feat len - {} \".format(len(rh_feats)))\n",
    "            sig_feats.extend(rh_feats)\n",
    "            fn_feats = kinetic_analysis(df_lg[df_lg['activity'] == 7]['pitch'],64,order=2,lf=1,hf=20, prom_val= (0.05,None), width_val = (None,20) ,Dist_val=5,detect_theshold=0)\n",
    "            sig_feats.extend(fn_feats)\n",
    "            hf_feats = kinetic_analysis(df_lg[df_lg['activity'] == 4]['pitch'],64,order=2,lf=1,hf=20, prom_val= (0.05,None), width_val = (None,20) ,Dist_val=5,detect_theshold=0)\n",
    "            sig_feats.extend(hf_feats)\n",
    "\n",
    "#             print(\"tot feat len - {} \".format(len(sig_feats)))\n",
    "            sig_feats.append(file_num)\n",
    "#             print(\"tot feat len - {} \".format(len(sig_feats)))\n",
    "            sig_feats.append(pno)\n",
    "#             print(\"tot feat len - {} \".format(len(sig_feats)))\n",
    "            sig_feats.append(medication_status)\n",
    "            print(\"tot feat len - {} \".format(len(sig_feats)))\n",
    "            feat_lg.append(sig_feats)\n",
    "            print(\"Total LG feat len - {} \".format(np.array(feat_lg).shape))\n",
    "\n",
    "            #         print(peak_valley_feats)\n",
    "        except ValueError:\n",
    "            print(\"Error in: {}\".format(file_num))\n",
    "            continue\n",
    "feat_arr = np.transpose(feat_lg)\n",
    "print(len(feat_lg))\n",
    "# df_rg = pd.DataFrame(feat_rg, columns = cnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c38fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rg = pd.DataFrame(feat_rg, columns = cnames)\n",
    "# df_lg = pd.DataFrame(feat_lg, columns = cnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad994a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ft_mean_p2p_dist</th>\n",
       "      <th>ft_std_p2p_dist</th>\n",
       "      <th>ft_pdenergy</th>\n",
       "      <th>ft_dysenergy</th>\n",
       "      <th>ft_psd</th>\n",
       "      <th>ft_mean_freq</th>\n",
       "      <th>ft_rms</th>\n",
       "      <th>hh_seg1_acc_pdenergy</th>\n",
       "      <th>hh_seg1_acc_dysenergy</th>\n",
       "      <th>hh_seg1_acc_df</th>\n",
       "      <th>...</th>\n",
       "      <th>hf_mean_p2p_dist</th>\n",
       "      <th>hf_std_p2p_dist</th>\n",
       "      <th>hf_pdenergy</th>\n",
       "      <th>hf_dysenergy</th>\n",
       "      <th>hf_psd</th>\n",
       "      <th>hf_mean_freq</th>\n",
       "      <th>hf_rms</th>\n",
       "      <th>fno</th>\n",
       "      <th>pno</th>\n",
       "      <th>med_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.542857</td>\n",
       "      <td>1.872246</td>\n",
       "      <td>0.169749</td>\n",
       "      <td>0.637038</td>\n",
       "      <td>0.802474</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.030138</td>\n",
       "      <td>0.177060</td>\n",
       "      <td>0.302064</td>\n",
       "      <td>1.9375</td>\n",
       "      <td>...</td>\n",
       "      <td>15.196078</td>\n",
       "      <td>9.048929</td>\n",
       "      <td>0.175781</td>\n",
       "      <td>0.565126</td>\n",
       "      <td>0.698766</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>30.742855</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.264706</td>\n",
       "      <td>2.810786</td>\n",
       "      <td>0.158823</td>\n",
       "      <td>0.729557</td>\n",
       "      <td>0.920990</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.151240</td>\n",
       "      <td>0.273827</td>\n",
       "      <td>2.3750</td>\n",
       "      <td>...</td>\n",
       "      <td>12.714286</td>\n",
       "      <td>4.802210</td>\n",
       "      <td>0.190682</td>\n",
       "      <td>0.624434</td>\n",
       "      <td>0.805955</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>47.697743</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.307692</td>\n",
       "      <td>2.445864</td>\n",
       "      <td>0.160514</td>\n",
       "      <td>0.645094</td>\n",
       "      <td>0.861767</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.044316</td>\n",
       "      <td>0.181298</td>\n",
       "      <td>0.231411</td>\n",
       "      <td>1.4375</td>\n",
       "      <td>...</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>6.774462</td>\n",
       "      <td>0.203529</td>\n",
       "      <td>0.626800</td>\n",
       "      <td>0.817210</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>36.810795</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.861111</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>0.213856</td>\n",
       "      <td>0.786169</td>\n",
       "      <td>0.954184</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.050456</td>\n",
       "      <td>0.132858</td>\n",
       "      <td>0.166840</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.947368</td>\n",
       "      <td>4.968042</td>\n",
       "      <td>0.177191</td>\n",
       "      <td>0.618259</td>\n",
       "      <td>0.751977</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>38.456086</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.033333</td>\n",
       "      <td>3.646764</td>\n",
       "      <td>0.186048</td>\n",
       "      <td>0.682106</td>\n",
       "      <td>0.841126</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.040875</td>\n",
       "      <td>0.233973</td>\n",
       "      <td>0.443467</td>\n",
       "      <td>3.1875</td>\n",
       "      <td>...</td>\n",
       "      <td>12.507246</td>\n",
       "      <td>6.800731</td>\n",
       "      <td>0.193604</td>\n",
       "      <td>0.561389</td>\n",
       "      <td>0.738626</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>31.348363</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.800000</td>\n",
       "      <td>2.625516</td>\n",
       "      <td>0.193527</td>\n",
       "      <td>0.795809</td>\n",
       "      <td>0.942052</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.046174</td>\n",
       "      <td>0.170787</td>\n",
       "      <td>0.281354</td>\n",
       "      <td>1.3750</td>\n",
       "      <td>...</td>\n",
       "      <td>9.545455</td>\n",
       "      <td>3.055952</td>\n",
       "      <td>0.171977</td>\n",
       "      <td>0.513473</td>\n",
       "      <td>0.636579</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>43.211824</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.851852</td>\n",
       "      <td>2.414519</td>\n",
       "      <td>0.187977</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.917697</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.055281</td>\n",
       "      <td>0.194333</td>\n",
       "      <td>0.292310</td>\n",
       "      <td>1.0625</td>\n",
       "      <td>...</td>\n",
       "      <td>11.238636</td>\n",
       "      <td>4.400399</td>\n",
       "      <td>0.205217</td>\n",
       "      <td>0.635454</td>\n",
       "      <td>0.821048</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>38.849348</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.535714</td>\n",
       "      <td>2.542245</td>\n",
       "      <td>0.175146</td>\n",
       "      <td>0.750267</td>\n",
       "      <td>0.916869</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.041782</td>\n",
       "      <td>0.182083</td>\n",
       "      <td>0.205445</td>\n",
       "      <td>3.6875</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>7.080882</td>\n",
       "      <td>0.189068</td>\n",
       "      <td>0.517631</td>\n",
       "      <td>0.694674</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>24.268899</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.615385</td>\n",
       "      <td>1.665878</td>\n",
       "      <td>0.172959</td>\n",
       "      <td>0.774509</td>\n",
       "      <td>0.945940</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.042491</td>\n",
       "      <td>0.185899</td>\n",
       "      <td>0.401506</td>\n",
       "      <td>1.6875</td>\n",
       "      <td>...</td>\n",
       "      <td>11.533333</td>\n",
       "      <td>4.769580</td>\n",
       "      <td>0.236900</td>\n",
       "      <td>0.571546</td>\n",
       "      <td>0.888568</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>36.490258</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.054054</td>\n",
       "      <td>1.469435</td>\n",
       "      <td>0.187165</td>\n",
       "      <td>0.508450</td>\n",
       "      <td>0.781223</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.025375</td>\n",
       "      <td>0.145910</td>\n",
       "      <td>0.288215</td>\n",
       "      <td>1.6250</td>\n",
       "      <td>...</td>\n",
       "      <td>12.738095</td>\n",
       "      <td>6.572162</td>\n",
       "      <td>0.191547</td>\n",
       "      <td>0.584175</td>\n",
       "      <td>0.768518</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>30.732896</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.051282</td>\n",
       "      <td>1.466703</td>\n",
       "      <td>0.177417</td>\n",
       "      <td>0.634661</td>\n",
       "      <td>0.846422</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.037571</td>\n",
       "      <td>0.213707</td>\n",
       "      <td>0.326241</td>\n",
       "      <td>1.6250</td>\n",
       "      <td>...</td>\n",
       "      <td>11.813953</td>\n",
       "      <td>3.499208</td>\n",
       "      <td>0.220715</td>\n",
       "      <td>0.659036</td>\n",
       "      <td>0.868821</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>42.430220</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17.611111</td>\n",
       "      <td>2.031389</td>\n",
       "      <td>0.194803</td>\n",
       "      <td>0.479649</td>\n",
       "      <td>0.767838</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.026617</td>\n",
       "      <td>0.151676</td>\n",
       "      <td>0.173148</td>\n",
       "      <td>1.5625</td>\n",
       "      <td>...</td>\n",
       "      <td>12.416667</td>\n",
       "      <td>4.026130</td>\n",
       "      <td>0.217215</td>\n",
       "      <td>0.563115</td>\n",
       "      <td>0.761271</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>39.057177</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17.968750</td>\n",
       "      <td>1.446642</td>\n",
       "      <td>0.186145</td>\n",
       "      <td>0.644641</td>\n",
       "      <td>0.877769</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.039449</td>\n",
       "      <td>0.164356</td>\n",
       "      <td>0.220108</td>\n",
       "      <td>2.1875</td>\n",
       "      <td>...</td>\n",
       "      <td>12.126582</td>\n",
       "      <td>3.650445</td>\n",
       "      <td>0.238759</td>\n",
       "      <td>0.583680</td>\n",
       "      <td>0.856645</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>39.741745</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18.545455</td>\n",
       "      <td>1.372697</td>\n",
       "      <td>0.189852</td>\n",
       "      <td>0.740448</td>\n",
       "      <td>0.903588</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.059083</td>\n",
       "      <td>0.150498</td>\n",
       "      <td>0.199429</td>\n",
       "      <td>1.1875</td>\n",
       "      <td>...</td>\n",
       "      <td>11.414286</td>\n",
       "      <td>3.310127</td>\n",
       "      <td>0.243264</td>\n",
       "      <td>0.587699</td>\n",
       "      <td>0.863672</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>35.796259</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17.566667</td>\n",
       "      <td>1.926713</td>\n",
       "      <td>0.186790</td>\n",
       "      <td>0.747870</td>\n",
       "      <td>0.888876</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.219504</td>\n",
       "      <td>0.269273</td>\n",
       "      <td>8.7500</td>\n",
       "      <td>...</td>\n",
       "      <td>12.776119</td>\n",
       "      <td>4.231442</td>\n",
       "      <td>0.248340</td>\n",
       "      <td>0.499302</td>\n",
       "      <td>0.739694</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>42.757588</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18.500000</td>\n",
       "      <td>2.392422</td>\n",
       "      <td>0.196182</td>\n",
       "      <td>0.713768</td>\n",
       "      <td>0.932017</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.061819</td>\n",
       "      <td>0.192397</td>\n",
       "      <td>0.215004</td>\n",
       "      <td>1.5625</td>\n",
       "      <td>...</td>\n",
       "      <td>16.411765</td>\n",
       "      <td>8.376382</td>\n",
       "      <td>0.150895</td>\n",
       "      <td>0.515341</td>\n",
       "      <td>0.600509</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>38.082930</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.583333</td>\n",
       "      <td>3.414634</td>\n",
       "      <td>0.184847</td>\n",
       "      <td>0.694779</td>\n",
       "      <td>0.872172</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>0.039247</td>\n",
       "      <td>0.151057</td>\n",
       "      <td>0.219096</td>\n",
       "      <td>1.8125</td>\n",
       "      <td>...</td>\n",
       "      <td>18.448980</td>\n",
       "      <td>9.897559</td>\n",
       "      <td>0.129750</td>\n",
       "      <td>0.438752</td>\n",
       "      <td>0.493439</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>37.936740</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.870968</td>\n",
       "      <td>2.136351</td>\n",
       "      <td>0.184843</td>\n",
       "      <td>0.631677</td>\n",
       "      <td>0.831598</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.037038</td>\n",
       "      <td>0.094653</td>\n",
       "      <td>0.105078</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>14.220339</td>\n",
       "      <td>7.135654</td>\n",
       "      <td>0.168959</td>\n",
       "      <td>0.658079</td>\n",
       "      <td>0.765336</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>41.032072</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17.514286</td>\n",
       "      <td>1.537557</td>\n",
       "      <td>0.196031</td>\n",
       "      <td>0.613325</td>\n",
       "      <td>0.843703</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.041901</td>\n",
       "      <td>0.199917</td>\n",
       "      <td>0.269746</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.886364</td>\n",
       "      <td>3.562532</td>\n",
       "      <td>0.234157</td>\n",
       "      <td>0.531431</td>\n",
       "      <td>0.798179</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>37.006582</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows  84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ft_mean_p2p_dist  ft_std_p2p_dist  ft_pdenergy  ft_dysenergy    ft_psd  \\\n",
       "0          18.542857         1.872246     0.169749      0.637038  0.802474   \n",
       "1          21.264706         2.810786     0.158823      0.729557  0.920990   \n",
       "2          21.307692         2.445864     0.160514      0.645094  0.861767   \n",
       "3          17.861111         2.043319     0.213856      0.786169  0.954184   \n",
       "4          18.033333         3.646764     0.186048      0.682106  0.841126   \n",
       "5          17.800000         2.625516     0.193527      0.795809  0.942052   \n",
       "6          19.851852         2.414519     0.187977      0.705833  0.917697   \n",
       "7          18.535714         2.542245     0.175146      0.750267  0.916869   \n",
       "8          19.615385         1.665878     0.172959      0.774509  0.945940   \n",
       "9          19.054054         1.469435     0.187165      0.508450  0.781223   \n",
       "10         19.051282         1.466703     0.177417      0.634661  0.846422   \n",
       "11         17.611111         2.031389     0.194803      0.479649  0.767838   \n",
       "12         17.968750         1.446642     0.186145      0.644641  0.877769   \n",
       "13         18.545455         1.372697     0.189852      0.740448  0.903588   \n",
       "14         17.566667         1.926713     0.186790      0.747870  0.888876   \n",
       "15         18.500000         2.392422     0.196182      0.713768  0.932017   \n",
       "16         17.583333         3.414634     0.184847      0.694779  0.872172   \n",
       "17         16.870968         2.136351     0.184843      0.631677  0.831598   \n",
       "18         17.514286         1.537557     0.196031      0.613325  0.843703   \n",
       "\n",
       "    ft_mean_freq    ft_rms  hh_seg1_acc_pdenergy  hh_seg1_acc_dysenergy  \\\n",
       "0       0.001006  0.030138              0.177060               0.302064   \n",
       "1       0.000916  0.065461              0.151240               0.273827   \n",
       "2       0.000954  0.044316              0.181298               0.231411   \n",
       "3       0.001133  0.050456              0.132858               0.166840   \n",
       "4       0.001099  0.040875              0.233973               0.443467   \n",
       "5       0.001024  0.046174              0.170787               0.281354   \n",
       "6       0.001034  0.055281              0.194333               0.292310   \n",
       "7       0.001044  0.041782              0.182083               0.205445   \n",
       "8       0.000996  0.042491              0.185899               0.401506   \n",
       "9       0.001129  0.025375              0.145910               0.288215   \n",
       "10      0.001050  0.037571              0.213707               0.326241   \n",
       "11      0.001218  0.026617              0.151676               0.173148   \n",
       "12      0.001181  0.039449              0.164356               0.220108   \n",
       "13      0.001007  0.059083              0.150498               0.199429   \n",
       "14      0.000980  0.050047              0.219504               0.269273   \n",
       "15      0.001074  0.061819              0.192397               0.215004   \n",
       "16      0.001130  0.039247              0.151057               0.219096   \n",
       "17      0.001140  0.037038              0.094653               0.105078   \n",
       "18      0.001105  0.041901              0.199917               0.269746   \n",
       "\n",
       "    hh_seg1_acc_df  ...  hf_mean_p2p_dist  hf_std_p2p_dist  hf_pdenergy  \\\n",
       "0           1.9375  ...         15.196078         9.048929     0.175781   \n",
       "1           2.3750  ...         12.714286         4.802210     0.190682   \n",
       "2           1.4375  ...         13.800000         6.774462     0.203529   \n",
       "3           2.0000  ...         10.947368         4.968042     0.177191   \n",
       "4           3.1875  ...         12.507246         6.800731     0.193604   \n",
       "5           1.3750  ...          9.545455         3.055952     0.171977   \n",
       "6           1.0625  ...         11.238636         4.400399     0.205217   \n",
       "7           3.6875  ...         13.000000         7.080882     0.189068   \n",
       "8           1.6875  ...         11.533333         4.769580     0.236900   \n",
       "9           1.6250  ...         12.738095         6.572162     0.191547   \n",
       "10          1.6250  ...         11.813953         3.499208     0.220715   \n",
       "11          1.5625  ...         12.416667         4.026130     0.217215   \n",
       "12          2.1875  ...         12.126582         3.650445     0.238759   \n",
       "13          1.1875  ...         11.414286         3.310127     0.243264   \n",
       "14          8.7500  ...         12.776119         4.231442     0.248340   \n",
       "15          1.5625  ...         16.411765         8.376382     0.150895   \n",
       "16          1.8125  ...         18.448980         9.897559     0.129750   \n",
       "17          1.2500  ...         14.220339         7.135654     0.168959   \n",
       "18          1.5000  ...         10.886364         3.562532     0.234157   \n",
       "\n",
       "    hf_dysenergy    hf_psd  hf_mean_freq     hf_rms  fno  pno  med_status  \n",
       "0       0.565126  0.698766      0.000583  30.742855    0    1           3  \n",
       "1       0.624434  0.805955      0.000631  47.697743    1    1           3  \n",
       "2       0.626800  0.817210      0.000715  36.810795    2    1           3  \n",
       "3       0.618259  0.751977      0.000705  38.456086    3    1           3  \n",
       "4       0.561389  0.738626      0.000699  31.348363    4    1           2  \n",
       "5       0.513473  0.636579      0.000565  43.211824    5    1           3  \n",
       "6       0.635454  0.821048      0.000805  38.849348    6    1           3  \n",
       "7       0.517631  0.694674      0.000620  24.268899    7    1           2  \n",
       "8       0.571546  0.888568      0.000978  36.490258    8    1           3  \n",
       "9       0.584175  0.768518      0.000504  30.732896    9    1           3  \n",
       "10      0.659036  0.868821      0.000851  42.430220   10    1           1  \n",
       "11      0.563115  0.761271      0.000799  39.057177   11    1           2  \n",
       "12      0.583680  0.856645      0.000914  39.741745   12    1           3  \n",
       "13      0.587699  0.863672      0.000886  35.796259   13    1           3  \n",
       "14      0.499302  0.739694      0.000729  42.757588   14    1           2  \n",
       "15      0.515341  0.600509      0.000604  38.082930   15    1           3  \n",
       "16      0.438752  0.493439      0.000494  37.936740   17    1           0  \n",
       "17      0.658079  0.765336      0.000762  41.032072   18    1           3  \n",
       "18      0.531431  0.798179      0.000842  37.006582   19    1           0  \n",
       "\n",
       "[19 rows x 84 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0334804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_rg = df_rg(df_rg['med_status']==0)\n",
    "# df_rg = df_rg.loc[df_rg['med_status'] != 0]\n",
    "# df_lg = df_lg.loc[df_lg['med_status'] != 0]\n",
    "# print(df_rg['med_status'].value_counts())\n",
    "# df_rg = df_rg.loc[df_rg['med_status'] != 2]\n",
    "# df_lg = df_lg.loc[df_lg['med_status'] != 2]\n",
    "# \n",
    "# df_rg = df_rg[df_rg['med_status']>0]\n",
    "# df_lg = df_lg[df_lg['med_status']>0]\n",
    "\n",
    "# Set medication status to binary variable 0-3hrs = 1 [on meds], 4+hrs = 0 [off meds]\n",
    "\n",
    "df_rg.loc[(df_rg['med_status'] <3,'med_status')]=1\n",
    "df_rg.loc[(df_rg['med_status'] ==3,'med_status')]=0\n",
    "df_lg.loc[(df_lg['med_status'] <3,'med_status')]=1\n",
    "df_lg.loc[(df_lg['med_status'] ==3,'med_status')]=0\n",
    "print(df_rg['med_status'].value_counts())\n",
    "print(df_lg['med_status'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# df_rg.loc[(df_rg['med_status'] <3,'med_status')]=1\n",
    "# df_rg.loc[(df_rg['med_status'] ==3,'med_status')]=0\n",
    "# df_lg.loc[(df_lg['med_status'] <3,'med_status')]=1\n",
    "# df_lg.loc[(df_lg['med_status'] ==3,'med_status')]=0\n",
    "\n",
    "\n",
    "# Compute relative features\n",
    "\n",
    "df_rg[\"rel_seg1_acc_energy\"] = df_rg[\"rh_seg1_acc_psd\"]/df_rg[\"hh_seg1_acc_psd\"]\n",
    "df_rg[\"rel_seg1_gyr_energy\"] = df_rg[\"rh_seg1_gyr_psd\"]/df_rg[\"hh_seg1_gyr_psd\"]\n",
    "df_rg[\"rel_seg2_acc_energy\"] = df_rg[\"rh_seg2_acc_psd\"]/df_rg[\"hh_seg2_acc_psd\"]\n",
    "df_rg[\"rel_seg2_gyr_energy\"] = df_rg[\"rh_seg2_gyr_psd\"]/df_rg[\"hh_seg2_gyr_psd\"]\n",
    "df_rg[\"rel_acc_zc\"] = df_rg[\"rh_acc_zc\"]/df_rg[\"hh_acc_zc\"]\n",
    "df_rg[\"rel_gyr_zc\"] = df_rg[\"rh_gyr_zc\"]/df_rg[\"hh_gyr_zc\"]\n",
    "df_rg[\"rel_ft_energy\"] = df_rg[\"ft_dysenergy\"]/df_rg[\"ft_pdenergy\"]\n",
    "\n",
    "df_lg[\"rel_seg1_acc_energy\"] = df_lg[\"rh_seg1_acc_psd\"]/df_lg[\"hh_seg1_acc_psd\"]\n",
    "df_lg[\"rel_seg1_gyr_energy\"] = df_lg[\"rh_seg1_gyr_psd\"]/df_lg[\"hh_seg1_gyr_psd\"]\n",
    "df_lg[\"rel_seg2_acc_energy\"] = df_lg[\"rh_seg2_acc_psd\"]/df_lg[\"hh_seg2_acc_psd\"]\n",
    "df_lg[\"rel_seg2_gyr_energy\"] = df_lg[\"rh_seg2_gyr_psd\"]/df_lg[\"hh_seg2_gyr_psd\"]\n",
    "df_lg[\"rel_acc_zc\"] = df_lg[\"rh_acc_zc\"]/df_lg[\"hh_acc_zc\"]\n",
    "df_lg[\"rel_gyr_zc\"] = df_lg[\"rh_gyr_zc\"]/df_lg[\"hh_gyr_zc\"]\n",
    "df_lg[\"rel_ft_energy\"] = df_lg[\"ft_dysenergy\"]/df_lg[\"ft_pdenergy\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3849b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4463fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file if needed\n",
    "# df_rg.to_csv(dset_path+'/rg_feats.csv')\n",
    "# df_lg.to_csv((dset_path+'/lg_feats.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "830b92ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['fno' 'pno'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2c046b5dc56c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeat_set_rg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_rg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfeat_set_rg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_set_rg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fno'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pno'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfeat_set_rg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_set_rg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/edear/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/edear/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4913\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4914\u001b[0m         )\n\u001b[1;32m   4915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/edear/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/edear/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/edear/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['fno' 'pno'] not found in axis\""
     ]
    }
   ],
   "source": [
    "## SHAP Analysis (right glove) for computing feature importance\n",
    "\n",
    "feat_set_rg = df_rg\n",
    "feat_set_rg = feat_set_rg.drop(['fno', 'pno'], axis=1) \n",
    "feat_set_rg = feat_set_rg.fillna(0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "# Spliiting data into test and train sets\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat_set_rg.drop('med_status', axis=1), feat_set_rg['med_status'], test_size=0.20, random_state=4)\n",
    "# fitting the model\n",
    "scaler = Normalizer().fit(feat_set_rg.drop('med_status', axis=1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=700, n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "# plotting feature importances\n",
    "features = feat_set_rg.drop('med_status', axis=1).columns\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(10,15))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n",
    "print( [features[i] for i in indices])\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test,plot_type=\"bar\",\n",
    "               show=False)\n",
    "fig = plt.gcf() # gcf means \"get current figure\"\n",
    "plt.rcParams['font.size'] = '14'\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams['axes.labelsize'] = '14'\n",
    "plt.rcParams['legend.fontsize'] = '14'\n",
    "\n",
    "\n",
    "ax = plt.gca() #gca means \"get current axes\"\n",
    "# leg = ax.legend(bbox_to_anchor=(0., 1.02, 1., .102))\n",
    "# for l in leg.get_texts(): l.set_text(l.get_text().replace('Class', 'Klasse'))\n",
    "plt.show()\n",
    "\n",
    "# perm_importance = permutation_importance(model, X_test, y_test)\n",
    "# sorted_idx = perm_importance.importances_mean.argsort()\n",
    "# plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "# plt.xlabel(\"Permutation Importance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SHAP Analysis (left glove) for computing feature importance\n",
    "\n",
    "feat_set_rg = df_lg\n",
    "feat_set_rg = feat_set_rg.drop(['fno', 'pno'], axis=1) \n",
    "feat_set_rg = feat_set_rg.fillna(0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "# Spliiting data into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat_set_rg.drop('med_status', axis=1), feat_set_rg['med_status'], test_size=0.20, random_state=4)\n",
    "# fitting the model\n",
    "model = RandomForestClassifier(n_estimators=700, n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "# plotting feature importances\n",
    "features = feat_set_rg.drop('med_status', axis=1).columns\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(10,15))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n",
    "print( [features[i] for i in indices])\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test,plot_type=\"bar\",\n",
    "               show=False)\n",
    "fig = plt.gcf() # gcf means \"get current figure\"\n",
    "plt.rcParams['font.size'] = '14'\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams['axes.labelsize'] = '14'\n",
    "plt.rcParams['legend.fontsize'] = '14'\n",
    "\n",
    "\n",
    "ax = plt.gca() #gca means \"get current axes\"\n",
    "# leg = ax.legend(bbox_to_anchor=(0., 1.02, 1., .102))\n",
    "# for l in leg.get_texts(): l.set_text(l.get_text().replace('Class', 'Klasse'))\n",
    "plt.show()\n",
    "\n",
    "# perm_importance = permutation_importance(model, X_test, y_test)\n",
    "# sorted_idx = perm_importance.importances_mean.argsort()\n",
    "# plt.barh(features[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "# plt.xlabel(\"Permutation Importance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.fit(X_train, y_train)\n",
    "predictions = cls.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc30a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_set_lg = df_lg\n",
    "feat_set_lg = feat_set_lg.drop(['fno', 'pno'], axis=1) \n",
    "feat_set_lg = feat_set_lg.fillna(0)\n",
    "\n",
    "# Spliiting data into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(feat_set_lg.drop('med_status', axis=1), feat_set_lg['med_status'], test_size=0.20, random_state=4)\n",
    "# fitting the model\n",
    "model = RandomForestClassifier(n_estimators=700, n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "# plotting feature importances\n",
    "features = feat_set_lg.drop('med_status', axis=1).columns\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.figure(figsize=(10,15))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n",
    "\n",
    "print( [features[i] for i in indices])\n",
    "\n",
    "\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test,plot_type=\"bar\",\n",
    "               show=False)\n",
    "fig = plt.gcf() # gcf means \"get current figure\"\n",
    "plt.rcParams['font.size'] = '14'\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams['axes.labelsize'] = '14'\n",
    "plt.rcParams['legend.fontsize'] = '14'\n",
    "\n",
    "\n",
    "ax = plt.gca() #gca means \"get current axes\"\n",
    "# leg = ax.legend(bbox_to_anchor=(0., 1.02, 1., .102))\n",
    "# for l in leg.get_texts(): l.set_text(l.get_text().replace('Class', 'Klasse'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = feat_set_rg.drop('med_status', axis=1).corr() # Generate correlation matrix\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        x = corr.columns,\n",
    "        y = corr.index,\n",
    "        z = np.array(corr)\n",
    "    )\n",
    ")\n",
    "\n",
    "# corr2 = feat_set_lg.drop('med_status', axis=1).corr() # Generate correlation matrix\n",
    "\n",
    "# fig2 = go.Figure()\n",
    "# fig2.add_trace(\n",
    "#     go.Heatmap(\n",
    "#         x = corr2.columns,\n",
    "#         y = corr2.index,\n",
    "#         z = np.array(corr2)\n",
    "#     )\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f2909",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2 = feat_set_lg.drop('med_status', axis=1).corr() # Generate correlation matrix\n",
    "fig2 = go.Figure()\n",
    "fig2.add_trace(\n",
    "    go.Heatmap(\n",
    "        x = corr2.columns,\n",
    "        y = corr2.index,\n",
    "        z = np.array(corr2)\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c10d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(i+1, corr.shape[0]):\n",
    "        if corr.iloc[i,j] >= 0.9:\n",
    "            if columns[j]:\n",
    "                columns[j] = False\n",
    "\n",
    "selected_columns_rg = feat_set_rg.drop('med_status', axis=1).columns[columns]\n",
    "df_rg_select = feat_set_rg[selected_columns_rg]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P-value code\n",
    "selected_columns_rg = selected_columns_rg[1:]\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def backwardElimination(x, Y, sl, columns):\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(Y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues).astype(float)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "                    columns = np.delete(columns, j)\n",
    "                    \n",
    "    regressor_OLS.summary()\n",
    "    return x, columns\n",
    "SL = 0.05\n",
    "data_modeled, selected_columns_rg = backwardElimination(df_rg_select.iloc[:,1:].values, df_rg_select.iloc[:,0].values, SL, selected_columns_rg)\n",
    "# data_modeled, selected_columns = backwardElimination(feat_set_rg.drop('med_status', axis=1).values, feat_set_rg['med_status'], SL, selected_columns)\n",
    "result = pd.DataFrame()\n",
    "result['med_status'] = feat_set_rg['med_status']\n",
    "print(len(selected_columns_rg))\n",
    "df_rg_select = pd.DataFrame(data = data_modeled, columns = selected_columns_rg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (25, 25))\n",
    "j = 0\n",
    "for i in selected_columns_rg:\n",
    "    plt.subplot(10, 8, j+1)\n",
    "    j += 1\n",
    "    sns.distplot(feat_set_rg[i][result['med_status']==0], color='g', label = 'Pre Medication')\n",
    "    sns.distplot(feat_set_rg[i][result['med_status']==1], color='r', label = 'Post Medication')\n",
    "    plt.legend(loc='best')\n",
    "fig.suptitle('RG Data Analysis')\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49382bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "for i in range(corr.shape[0]):\n",
    "    for j in range(i+1, corr.shape[0]):\n",
    "        if corr.iloc[i,j] >= 0.9:\n",
    "            if columns[j]:\n",
    "                columns[j] = False\n",
    "selected_columns_lg = feat_set_lg.drop('med_status', axis=1).columns[columns]\n",
    "df_lg_select = feat_set_lg[selected_columns_lg]\n",
    "selected_columns_lg = selected_columns_lg[1:]\n",
    "# P-value code\n",
    "SL = 0.05\n",
    "data_modeled, selected_columns_lg = backwardElimination(df_lg_select.iloc[:,1:].values, df_lg_select.iloc[:,0].values, SL, selected_columns_lg)\n",
    "# data_modeled, selected_columns = backwardElimination(feat_set_rg.drop('med_status', axis=1).values, feat_set_rg['med_status'], SL, selected_columns)\n",
    "result = pd.DataFrame()\n",
    "result['med_status'] = feat_set_lg['med_status']\n",
    "df_lg_select = pd.DataFrame(data = data_modeled, columns = selected_columns_lg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (25, 25))\n",
    "j = 0\n",
    "for i in data_lg.columns:\n",
    "    plt.subplot(10, 8, j+1)\n",
    "    j += 1\n",
    "    sns.distplot(data_lg[i][result['med_status']==0], color='g', label = 'Pre Medication')\n",
    "    sns.distplot(data_lg[i][result['med_status']==1], color='r', label = 'Post Medication')\n",
    "    plt.legend(loc='best')\n",
    "fig.suptitle('LG Data Analysis')\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403b7dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_set_rg_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f9f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_rg[df_rg['activity'] == 6][ch_]\n",
    "fig = px.box(data_frame = df_lg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'hf_mean_p2p_dist'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "#     legend=dict(\n",
    "#     yanchor=\"bottom\",\n",
    "#     y=0.0,\n",
    "#     xanchor=\"right\",\n",
    "# #     x=0.01\n",
    "#     ),\n",
    "    title={\n",
    "        'text': \"Left Glove - Hand Flip Mean Peak to Peak distance\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'bottom'},\n",
    "    xaxis_title=\"Participant\",\n",
    "    yaxis_title=\"Sample difference\",\n",
    "    font=dict(\n",
    "        family=\"Times New Roman, monospace\",\n",
    "        size=18,\n",
    "        color=\"Black\"\n",
    "    ))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a25ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(df_lg, y=\"hf_mean_p2p_dist\", x=\"pno\", color=\"med_status\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b389c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# tips = sns.load_dataset('tips')\n",
    "\n",
    "# Define some hatches\n",
    "hatches = cycle(['///', 'x'])\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(x=\"pno\", y=\"hf_mean_p2p_dist\", hue=\"med_status\", data=df_lg)\n",
    "for i, patch in enumerate(ax.artists):\n",
    "    # Boxes from left to right\n",
    "    hatch = next(hatches)\n",
    "    patch.set_hatch(hatch)\n",
    "\n",
    "ax.axes.set_title(\"Left Hand Flip peak to peak distance\", fontsize=16)\n",
    "ax.set_xlabel(\"Participants\", fontsize=14)\n",
    "ax.set_ylabel(\"Mean peak to peak distance\", fontsize=14)\n",
    "ax.legend([],[], frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00865e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(df_lg, y=\"rh_seg2_gyr_mf\", x=\"pno\", color=\"med_status\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# tips = sns.load_dataset('tips')\n",
    "\n",
    "# Define some hatches\n",
    "hatches = cycle(['///', 'x'])\n",
    "\n",
    "# Boxplot\n",
    "ax = sns.boxplot(x=\"pno\", y=\"rh_seg2_gyr_mf\", hue=\"med_status\", data=df_rg)\n",
    "for i, patch in enumerate(ax.artists):\n",
    "    # Boxes from left to right\n",
    "    hatch = next(hatches)\n",
    "    patch.set_hatch(hatch)\n",
    "\n",
    "ax.axes.set_title(\"Right Hand resting hand mean frequency\", fontsize=16)\n",
    "ax.set_xlabel(\"Participants\", fontsize=14)\n",
    "ax.set_ylabel(\"Mean Frequency (Hz)\", fontsize=14)\n",
    "# ax.legend([],[], frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig.update_layout(\n",
    "#     legend=dict(\n",
    "#     yanchor=\"bottom\",\n",
    "#     y=0.0,\n",
    "#     xanchor=\"right\",\n",
    "# #     x=0.01\n",
    "#     ),\n",
    "    title={\n",
    "        'text': \"Left Glove - Hand Flip Mean Peak to Peak distance\",\n",
    "        'y':0.9,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'bottom'},\n",
    "    xaxis_title=\"Participant\",\n",
    "    yaxis_title=\"Relative Energy (a.u)\",\n",
    "    font=dict(\n",
    "        family=\"Times New Roman, monospace\",\n",
    "        size=18,\n",
    "        color=\"Black\"\n",
    "    ))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1de476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'rel_acc_zc'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316fd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'rh_seg2_acc_mf'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_lg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'hf_std_p2p_dist'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068980c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'rh_seg2_gyr_psd'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'hh_seg2_gyr_psd'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c27fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'rh_seg2_gyr_df'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51683e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'rh_seg2_gyr_df'\n",
    "       ,color= 'med_status'\n",
    "#        ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd2ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'hh_seg2_gyr_df'\n",
    "       ,color= 'med_status'\n",
    "#        ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c1fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'hh_seg2_acc_df'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b378c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'rh_seg2_gyr_df'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbcd74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_lg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'hh_seg2_gyr_df'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_lg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'hf_pdenergy'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf1cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_lg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'hf_pdenergy'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180b84b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'rel_seg2_gyr_energy'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b5767",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_lg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'rel_seg2_gyr_energy'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'rel_seg2_gyr_energy'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ac156",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'rh_seg2_acc_psd'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909f9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_lg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'rh_seg2_acc_psd'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7175105",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'rh_seg2_gyr_psd'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b92759",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'rel_seg1_gyr_energy'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d35e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'hh_seg2_acc_dysenergy'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bafaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'hh_gyr_zc'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e23eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data_frame = df_rg\n",
    "       ,x = 'pno'\n",
    "       ,y = 'hh_seg1_mean_freq'\n",
    "       ,color= 'med_status'\n",
    "       ,points=\"all\"\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89584b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_rg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa3888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_rg = pd.DataFrame(feat_rg,columns = ['ax','ay','az','gx','gy','gz','index','thumb','middle'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba68606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc_rms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "4fda0b754a13b9dfec1029e35c98a5438678fa8b1ab75998cbf927350000ebfa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
